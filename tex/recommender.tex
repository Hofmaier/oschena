\documentclass[a4paper, 12pt]{article}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{pgfplots}
\usepackage{graphicx}
\pgfplotsset{compat=1.9}
\usepackage{tikz}
\usepackage{float}
\author{Lukas Hofmaier}
\title{Userbased Collaborative Filtering und Matrixfaktorisierung}
\begin{document}

\lstset{basicstyle=\small,
language=Haskell,
stringstyle=ttfamiliy
}

\maketitle
\newpage
\tableofcontents
\newpage
\begin{abstract}
 Recommender Systeme nutzen Datenbanken mit Userpreferenzen, um dem User aus einer grossen Menge von Objekten, diejenigen zu empfehlen, die er noch nicht gesehen hat und die ihn interessieren k"onnten. Dieser Report konzentriert sich auf Collaborativ Filtering. Collaborative Filtering ist eine Klasse von Recommender, die Empfehlungen aufgrund von Preferenzen anderer User berechnet.
In diesem Report werden zwei Collaborative Filtering Methoden beschrieben. Userbased Collaborative Filtering ist eine der ersten und intuitivsten Methoden. Matrixfaktorisierung ist eine weitere Methode, die an der Netflix Competition die besten Resultate lieferte.

Die Algorithmen werden mit einer geeigneten Evaluation verglichen. Die Evaluation und die Algorithmen wurden in Haskell implementiert.

\end{abstract}

\section{Recommender-Problem}
\label{sec:problem}
Dieser Abschnitt beschreibt, was ein Recommendersystem ist und weshalb es einen Mehrwert schaffen kann.

Konsumenten werden heute in vielen Bereichen mit einer un"uberschaubaren Anzahl an Kaufm"oglichkeiten konfrontiert. In einem Webshop f"ur B"ucher oder Filme ist es es f"ur den Konsumenten beispielsweise schwierig, alle Artikel im Angebot anzuschauen und aufgrund dieser Evaluation die besten Artikel auszuw"ahlen. Beim Recommender-Problem geht es darum aus einer Mengen von Artikel (Items) ein sortierte Liste mit den empfehlenswertesten Artikel f"ur einen spezifischen Kunden (User) zu erstellen. Recommender kommen vorallem dort zum Einsatz, wo pers"onlicher Geschmack bei der Bewertung von Artikel eine wichtige Rolle spielt.

Ein Recommendersystem kann eine Bewertung absch"atzen (vorhersagen), die ein bestimmter User einem bestimmten Item gibt. Recommender berechnen die Bewertungen f"ur Items, die der User noch nicht gesehen hat. Die Items mit den besten Bewertungen werden dem User empfohlen.

Recommendersysteme werden vorallem im e-Commerce eingesetzt. Man kann sie aber auch dazu verwenden um unwichtige Informationen von wichtigen zu trennen. Recommender k"onnen beispielsweise auch f"ur Information Retrieval eingesetzt werden. Sie generieren eine Liste von Dokumenten die der User noch nicht gesehen hat \cite{herlocker00}.

In nachfolgenden Text wird haupts"achlich von User und Items gesprochen. Sie sind folgendermassen definiert.

\begin{description}
\item[User] User sind die Konsumenten oder f"ur die eine Empfehlung erstellt werden soll. 
User haben Preferencen und bewerten Items aufgrund des pers"onlichen Geschmacks. In einer Information Retrieval Anwendung k"onnen User auch einfach die Benutzer der Software sein.
\item[Item] 
Items k"onnen Artikel, Filme, B"ucher, Dokumente e.t.c sein. Items werden den Usern empfohlen.
\end{description}

Der aktive User bezeichnet den User, f"ur den Empfehlungen erstellt werden soll \cite{jannach11}.

Es gibt zwei unterschiedliche Strategien f"ur Recommendersysteme: Content filtering und Collaborative Filtering. Dieser Report besch"aftigt sich nur mit Collaborative Filtering Methoden. 

\subsection{Contentbased Filtering}
\label{sec:contentbased}

Bei Contentbased Filtering wird zu jedem Artikel und zu jedem User ein Profil erstellt. Dieses Profil enth"alt Informationen "uber die Eigenschaften von User und Item. Beispielsweise k"onnte man alle angebotenen Filme nach ihrer Genrezugeh"origkeit bewerten. Ein Film hat beispielsweise einen Action und einen Romantikanteil. User k"onnen angeben, ob sie lieber Action oder Romantik m"ogen. Content based Filtering sucht dann Filme, die am besten mit dem Userprofile matchen. Die Schwierigkeit an Content based Filtering ist das Erfassen von Daten zu jedem Item und zu jedem User. Jemand muss jeden Artikel im Angebot nach seinem Content bewerten. Von jedem User muss ein Profil erstellt werden. Der User kann seine Preferenzen oft selber eingeben. Denn meisten User ist das zu m"uhsam.

\subsection{Collaborative Filtering}
\label{sec:collaborativefiltering}

Collaborative Filtering ist eine weitere M"oglichkeit das Re\-commender-Prob\-lem zu l"osen. Bei Collaborative Filtering wird das Verhalten von User in der Vergangenheit analisiert. Dabei werden Bewertungen oder Transaktionen angeschaut. Der Inhalt der Artikel ist egal. Da diese Strategie unab"angig vom Inhalt ist kann sie f"ur jedes beliebige Recommendersystem eingesetzt werden. Es kann also im e-Commerce sowie auch im Information Retrieval eingesetzt werden.  Es wird in vielen Webshops erfolgreich eingesetzt \cite{sarwar01}. 

Ziel des Collaborative Filtering ist, es einem User neue Items oder f"ur ein bestimmtes Item und einen bestimmten User eine Bewertung vorauszusagen. Typischweise gibt es eine Menge von $m$ Usern  $\mathnormal{U}$ und eine Menge von $ \mathnormal{I} $ Items. Jeder User $\mathnormal{u}$ hat eine Liste $\mathnormal{I_u}$ von Items, welche er bewertet hat. Diese Bewertung wird meisten als numerischer Wert in einem Intervall ausgedr"uckt. Bei Filmen hat es sich zum beispiel durchgesetzt das man eine Zahl zwischen 1 und 5 angibt, wobei die 5 aussagt, dass der Film dem User gefallen hat und eine 1 bedeutet, dass dem User der Film nicht gefallen hat.. Diese Bewertungen werden von den User explizit eingegeben oder sie werden zum beispiel vom Kaufverhalten abgeleitet.

\subsubsection{Abgrenzung zu Contentbased Filtering}
\label{sec:definitioncf}

Bei Collaborative Filtering geht man davon aus, dass man die Bewertungen anderer User dazu benutzen kann, um dem aktiven User ein Item zu empfehlen, dass er noch nicht gesehen hat. Im Unterschied zu Contentbased Filtering ist der Inhalt des Items f"ur die Empfehlung nicht relevant. Das einzige was z"ahlt sind die Bewertungen anderer User.

\subsubsection{Vor- und Nachteile}
\label{sec:advandage}

Gegen"uber Contentbased Filtering bietet Collaborative Filtering folgenden Vor- und Nachteile.
\begin{description}
\item[Kein Wissen "uber Inhalt n"otig] Es muss nicht jedes Item nach seinem Content dursucht werden. Meisten ist der Inhalt im Kontext der Empfehlung nicht brauchbar (L"ange, Kategorie, Jahr).
\item[Usergeschmack "andert] Collaborativ Filtering passt sich automatisch an.
\item[Intuitiv] Jeder versteht "Kunden die diesen Artikel gekauft haben, haben auch diese Artikel gekauft.
\end{description}

\subsubsection{Resultate von Collaborative Filtering}
\label{sec:output}

Man kann zwei Resultate von Collaborative Filtering unterscheiden (siehe Abbildung \ref{fig:cfprocess}.

\begin{description}
\item[Prediction] Das System berechnet eine wahrscheinliche Vorhersage $P_{u,i}$ f"ur eine Bewertung von Item i und User u
\item[Empfehlung] Das System gibt eine Liste von $N$ Items zur"uck, die Items in der Liste hat der user noch nicht bewertet und das System hat die h"ochsten Bewertungen f"ur den aktiven User berechnet.
\end{description}

\begin{figure}
  \centering
      \includegraphics[width=0.5\textwidth]{cf}
  \caption{Collaborative Filtering Prozess}
  \label{fig:cfprocess}
\end{figure}

\subsubsection{Nearest-Neighbor vs. Latent Factor Models}
\label{sec:cfmodels}

Collaborative Filtering kann weiter in zwei unterschiedliche Methoden aufgeteilt werden:

\begin{description}
\item[Neighboorhood Methoden] Bei Neighboorhood Methoden werden f"ur jeden User "ahnliche User gesucht. Es wird eine Nachbarschaft mit "ahnlichen User erstellt.
"Ahnlichkeit wird aufgrund von gemeinsam bewerteten Item berechnet. Wenn zwei User f"ur mehrere Items die selben Bewertungen vergeben, sind sie sich "ahnlich. Sie haben einen "ahnlichke Einem User werden diejenigen Items empfohlen, die er noch nicht kennt und die eine hohe Bewertung von "ahnlichen Usern erhalten haben.
M"ochte man das Rating von einem User f"ur ein bestimmtes Item ab\-sch"atz\-en, schaut man, ob User in der Nachbarschaft das Item bereits bewertet haben. Aufgrund der "Ahnlickeit und den vorhandenen Ratings berechnet man das Rating das der User f"ur dieses Item abgeben w"urde.
\item[Latent Factor Model] Latent Factor Modelle repr"asentieren User und Items als Vektoren. Die Elemente sind Prefenzen und Eigenschaften. Diese Vektoren werden aufgrund der vorhandenen Bewertungen berechnet.
\end{description}

Dieser Report beschreibt Algorithmen f"ur beide Modele. Userbased ist eine Neighborhood Methode. Matrixfaxtorisation nutzt ein Latent Factor Model.

\subsection{Herausforderungen}
\label{sec:challenges}

Bei der Implementierung von Recommendersystemen ergeben sich mehrere Herausforderungen.

\begin{description}
\item[Genauigkeit] Die Differenz der Empfehlungen, die das Recommendersystem macht, soll so wenig wie m"oglich von der tats"achlichen Bewertung abweichen.
\item[Skalierbarkeit] 
Collaborative Filtering muss f"ur Millionen User und Items m"oglich sein. Die Technik soll also f"ur grosse Datenmengen skalieren.
\item[Sparsity] F"ur eine grosse Menge an Items gibt es in der Regel nur eine kleine Anzahl an Items, die ein User auch bewertet hat. Wenn sich keine gemeinsamen Items zwischen den Usern finden k"onnen auch keine Nachbarschaften gebildet werden.
\end{description}

\section{Evaluation}
\label{sec:evaluation}

In diesem Report werden mehrere L"osungen f"ur das Recommenderproblem beschrieben. Um die Qualit"at der Methoden zu messen werden die unterschiedlichen L"osungen miteinander verglichen. Die Qualit"at wird durch die Genauigkeit der Bewertungsvorhersagen beschrieben. Man misst die Differenz zwischen vorhergesagter und tats"achlicher Bewertung.

Dieser Abschnitt beschreibt eine Methode um die Qualit"at der Algorithmen zu evaluieren. In den nachfolgenden Abschnitten werden die Algorithmen mit dieser Methode evaluiert und miteinader verglichen.

\subsection{Daten}
\label{sec:data}

Ein Recommenderalgorithmus ben"otigt Daten um das Model zu erstellen. F"ur die Evaluation sind ebenfalls vorhandende Bewertungen notwendig. Diese Daten liegen oft in Form einer Matrix vor. Die Zeilen rep"asentieren Items und die Kolonnen User. In den Zellen steht welche Bewertung ein User einem Item gegeben hat. Diese Matrix nennt man Ratingmatrix.

Die Daten f"ur Recommender Systeme k"onnen auf zwei unterschiedliche Arten beschafft werden.

\begin{description}
\item[Explizites Feedback] Bei explizitem Feedback verl"asst man sich auf Daten die User explizit eingegen haben. Beispielsweise werden User aufgefordert, dem System ihre Preferenzen anzugeben oder man pr"asentiert den User eine Reihe von Items, die er auf einer Skala von 1 bis 5 bewerten muss. Ein Problem von explizitem Feedback ist, dass es oft zu d"unn besetzten Ratingmatrizen f"uhrt, da die User keine Zeit haben um alle verf"ugbaren Items zu bewerten.
\item[Implizites Feedback] Implizites Feedback leitet die Bewertungen der User f"ur Items aus Beobachtungen ab. Das System beobachtet die Interaktionen, wie zum Beispiel in Vergangheit gekaufte Artikel, Browsehistory, Suchanfragen oder Klickverhalten, des User mit dem System. Oft besteht implizites Feedback nur aus boolschen Werten. Das heisst entweder ein Ereignis ist eingetreten oder nicht.
\end{description}

 Der User-based Collaborative Filtering Algorithmus berechnet zu jedem User-Paar eine "Ahnlichkeit und zu jedem User eine Nachbarschaft. Das System berechnet die "Ahnlichkeiten auftrund der Ratingmatrix. Diese gibt Auskunft dar"uber, welche Bewertung die User den Items gegeben haben.

\subsubsection{MovieLens Daten}
\label{sec:movielens}

F"ur das Projekt wurden die Daten von Movielens verwendet. MovieLens wurde von vom GroupLens Projekt an der Universit"at Minnesota entwickelt. Die Daten werden mit einer Webanwendung gesammelt. User k"onnen Filme bewerten und MovieLens gibt den User darauf eine Top-N Empfehlungsliste. Die Daten k"onnen von http://www.grouplens.org/node/12 heruntergeladen werden. 

Das Datenset enth"alt die Bewertung von 943 User und 1682 Items. Die Daten sind in Kolonnen strukturiert. Die erste und zweite Kolonne enth"alt User und Item ID. Die dritte Kolonne enth"alt ein Zahl zwischen 1 und 5. Die repr"asentiert die Bewertung. Und in der vierten Kolonne ist ein Timestamp der Bewertung. Das Movielens Datenset enth"alt insgesamt 100000 Bewertungen. Abbildlung \ref{fig:movielens} zeigt einen Auschnitt der rohen Daten.

\begin{figure}
\centering
\begin{verbatim}
1	1	5	874965758
1	2	3	876893171
1	3	4	878542960
1	4	3	876893119
1	5	3	889751712
\end{verbatim}
\caption{Ausschnitt aus MovieLens Datensatz}
\label{fig:movielens}
\end{figure}

F"ur den Userbased Collaborative Filter Algorithmus wurden die Daten in das CSV-Format transfomiert. Die Daten wurden mit dem Pythonskript \verb|tocsv| transformiert. Das CSV-Format eignet sich bessser, weil vorhandene Libraries f"ur das Einlesen der Daten genutzt werden k"onnen. In diesem Projekt wurden die Daten mit Paket \verb|cassava| eingelesen.

F"ur die Matrixfaktorisierung wurden die Daten in als Matrix abgespeichert. So muss das Programm nicht bei jedem Testlauf die Transformation von 100000 Bewertungen in eine Ratingmatrix vornehmen.

\subsection{Vorgehen}
\label{sec:procedure}

Zur Evaluierung der Algorithmnen wurde die sogenannte Kreuzvalidierung angewendet. Die Evaluierung wird in zwei Phasen aufgeteilt. In Abbildung \ref{fig:crossvalidation} stellt diese grafisch dar.
\begin{enumerate}
\item Trainingsphase
\item Testphase
\end{enumerate}

Um Evaluationsmetriken zu bestimmen, werden die gegeben Daten ebenfalls in ein Trainings und ein Testset aufgeteilt. In diesem Projekt wurde das Set in 80000 Bewertungen f"ur die Trainingsphase und 20000 Bewertungen f"ur die Evaluierung aufgeteilt.

In der Trainingsphase berechnet das Recommendersystem das Model. Im Falle des Userbased Collaborative Filtering werden f"ur alle User die "Ahnlichkeiten zu anderen User berechnet. Bei der Matrixfaktorisierung werden in der Trainingsphase die Featurevektoren berechnet. 

In diesem Projekt wurde das Set in 80000 Bewertungen f"ur die Trainingsphase und 20000 Bewertungen f"ur die Evaluierung aufgeteilt.

\begin{figure}
  \centering
      \includegraphics[width=0.5\textwidth]{evaluation}
  \caption{Kreuzvalidierung}
  \label{fig:crossvalidation}
\end{figure}

Das Model der Trainingsphase wird in der Testphase verwendet. Mit dem berechneten Model muss der Recommender zu jeder Bewertung des Testset eine Bewertung vorhersagen ohne die tats"achliche Bewertung zu kenne. Diese Vorhersage vergleicht man mit dem tats"achlichen Bewertung aus dem Testset. Die Abweichungen vom tats"achlichen Wert nennt man Residuen. 

\subsection{Evaluationsmetrik}
\label{sec:evaluationmetrik}

Die Qualit"at des Recommendersystem kann mit Evaluationsmetriken "uberpr"uft werden. Evaluationsmetriken geben Auskunft dar"uber wie gut das Recommendersystem ist. Idealerweise kann ein Recommendersystem die Bewertung f"ur einen User und ein Item vorhersagen. Statistische Genauigkeitsmetriken geben an wie weit entfernt die Vorhersage vom tats"achlichen Wert ist. 

Es gibt verschieden Evaluationsmetriken. In diesem Projekt wurde der Mean Absolute Error als Metrik verwendet. MAE vergleicht die tats"achliche Bewertung eines User f"ur ein Item mit der Bewertung, die der Recommender berechnet hat. Man bildet die Differenz von Vorhersage und tats"achlicher Bewertung. Von der Differenz wird der Betrag berechnet. Schliesslich bestimmt man die mittlere Abweichung, indem man durch Anzahl Bewertungen $N$ im Testset teilt 

Der MAE ist wie folgt definiert \cite{sarwar01}:

\begin{equation}
  \label{eq:mae}
  MAE = \frac{\sum_{i+1}^N | p_i-q_i | }{N}
\end{equation}

Je tiefer der MAE, desto besser ist die Genauigkeit des Recommender.

Root Mean Squared Error und Correlation sind zwei weitere Metriken.

\subsection{Hardware Plattfrom}
\label{platform}

Die Experimente wurden auf einem PC-Notebook durchgef"uhrt. Der Notebook hat 8GB Ram und die CPU ist mit 2.9Ghz getaktet.

\begin{center}
\begin{tabular}{ll}
 Prozessor        &  i7-3520M            \\
 Clock            &  2.90GHz             \\
 Arbeitsspeicher  &  8 GB                \\
 Betriebssystem   &  Ubuntu 14.04.1 LTS  \\
\end{tabular}
\end{center}


\section{Unpers"onliche Empfehlungstechniken}
\label{sec:simple}

Dieser Abschnitt beschreibt einfache, alternative, M"oglichkeiten relative gute Empfehlungen zu generieren. Diese Techniken werden in den nachfolgenden Abschnitten als Baselinealgorithmus verwendet um zu "uberpr"ufen, ob das Recommendersystem eine h"ohere Genauigkeit erzielt. So ist einfach ersichtlich, ob die Collaborative Filtering Algorithmen einen qualitativen Vorteil bringen.

Um einem User Items zu empfehlen werden oft einfache Statistiken berechnet. Diese Methoden sind unpers"onlich. Das heisst die Top-N Empfehlungen sind nicht vom pers"onlichem Geschmack von $u$ abh"angig. Jeder User erh"alt die selben Empfehlungen. 

Diese Technik wird in vielen Bereichen angewendet. Restaurantf"uhrer oder Filmkritikwebseiten erstellen oft Ranglisten, welche Restaurants oder Filme von allen Usern im Durchschnitt am besten bewertet werden. Items mit den h"ochsten Durchschnittswerten, werden dem User empfohlen \cite{jannach11}.

Die einfachste Methode eine unbekannte Bewertung $b_{i,i}$ abzusch"atzen, ist den Durschnitt aller Bewertungen zu berechnen.

\begin{equation}
  \label{eq:avg}
  b_{u,i} = \mu
\end{equation}

Wenn diese Methode wie in Abschnitt \ref{sec:procedure} evaluiert wird, erh"alt man einen MAE von 0.968. Dieser Wert kann noch weiter minimiert werden.

Bestimmte User vergeben durchschnittlich tiefere Bewertungen. Diese Tendenz $b_u$ kann man f"ur jeden User berechnen. Man berechnet die Abweichung des Erwartungswertes $\mu$.

\begin{equation}
  b_u = \frac{1}{|I_u|}\sum_{i \in I_u}(r_{u,i} - \mu)
\end{equation}

Die Menge $I_u$ beinhaltet alle Items, die der User $u$ bewertet hat. $r_{u,i}$ ist die Bewertung die User $u$ Item $i$ gegeben hat.

Die Abweichung $b_u$ wird bei der Vorhersage zu $\mu$ addiert, um bei der Evaluation einen besseren MAE zu erhalten.

\begin{equation}
  \label{eq:bui}
  b_{u,i} = \mu + b_u
\end{equation}

Wenn man die Tendenz der User, Item durchschnittlich h"oher oder tiefer zu bewerten, ber"ucksichtig wie in der Gleichung \ref{eq:bui} beschrieben, kann man den MAE auf 0.8501 senken. 

Items haben ebenfalls eine Abweichung vom Durchschnitt. Bestimmte Filme zum beispiel k"onnen tendenziel eine h"ohere Bewertung von allen Usern erhalten. Es kann also noch die Abweichung $bi$ jedes Items berechnet werden.

\begin{equation}
  \label{eq:bi}
  b_i = \frac{1}{|U_i|}\sum_{u \in U_i}(r_{u,i} - b_u - \mu)
\end{equation}

Diese Abweichung addiert man zur Vorhersage $b_{ui}$.

\begin{equation}
  \label{eq:baseline}
  b_{u,i} = \mu + b_u + b_i
\end{equation}

Wenn man die statistischen Abweichungen der einzelnen User und Items bei der Vorhersage einer Bewertung $b_{ui}$ wie in Gleichung \ref{eq:baseline} ber"ucksichtig, erreicht man einen MAE von 0.76814.

$b_{ui}$ kann relativ einfach aufgrund der vergangen Bewertungen berechnet werden.

Listing \ref{lst:baseline} zeigt die Implemenation der Baseline Algorithmen.

\begin{lstlisting}[caption=Baseline predictor, label=lst:baseline]
import Math.Statistics
bui :: User -> Item -> Double
bui u i = mu + bu + bi
  where mu = avg allratings
        bu = computebu u
        bi = computebu i

computebu :: User -> Double
computebu u = sum ratings / nrOfratings
              where ratings = lookup u usermap
                    nrOfratings = length ratings

computebi :: Item -> Double
computebi i = sum ratings / nrOfratings
              where ratings = lookup i itemmap
                    nrOfratings = length ratings
\end{lstlisting}

$\mu$ kann einfach berechnet werden. Das Modul \verb|Math.Statistics| stellt die Funktion \verb|avg| zur Verf"ugung. \verb|allratings| gibt eine Liste aller Bewertungen zuru"ck. \verb|usermap| und \verb|itemmap| sind Maps. Die Funktion \verb|lookup| l"auft in O(logn).

In Diagramm \ref{fig:maebaselines} werden die verschiedenen, unpers"onlichen Recommender miteinander verglichen. Die Kombination aus Durchschnitt und Abweichung vom Durschnitt kann die Bewertungen der User am besten vorhersagen. Das Diagramm zeigt den Mean Absolute Error. Dieser Wert ist kurz gesagt der Durchschnitt der Abweichung der Vorhersage von tats"achlichen Wert.

\begin{figure}
  \centering
\begin{tikzpicture}
  \begin{axis}[
    xbar, xmin=0,
    width=12cm, enlarge y limits=0.5,
    symbolic y coords = {Durchschnitt,Item-AVG,User-AVG,$b_{ui}$},
    xlabel={MeanAbsoluteError},
    ytick = data,
    nodes near coords, nodes near coords align={horizontal},
    ]
    \addplot coordinates {(0.9680,Durchschnitt) (0.930,User-AVG) (0.877,Item-AVG) (0.861,$b_{ui}$)};
  \end{axis}
\end{tikzpicture}
  
  \caption{Vergleich: unpers"onliche Empfehlungen}
  \label{fig:maebaselines}
\end{figure}


\section{Userbased Collaborative Filtering}

Die Technik Userbased Collaborative Filtering ist auch als k-NN (nearest-neighbor) oder Memory-based Collaborative Filtering bekannt. Der GroupLens Usenet Articel Recommender verwendete als einer der ersten Recommender Systeme Userbased Collaborative Filtering. Ringo Music Recommender und der Bell Core Video Recommender verwenden auch Userbased CF \cite{ekstrand11}.

Userbased Collaborative filtering kann in zwei Schritte aufgeteilt werden. 

\begin{description}
\item[Nachbarschaft bestimmen] F"ur jeden User $u$ wird eine Nachbarschaft $N \subseteq U$ erstellt. Diese Nachbarschaft enth"alt Tupel mit anderen Usern und deren "Ahnlichkeit $sim$ zu $u$. Die Nachbarschaft ist sortiert nach "Ahnlichkeit. Die Nachbarschaft wird aufgrund der Trainingsdaten erstellt. Sie stellt das Model von Userbased Collaborative Filtering dar. Wenn im zweiten Schritt eine unbekannte Bewertung abgesch"atzt wird, wird auf die vorberechneten Nachbarschaften zugegriffen.
\item [gewichtetes Mittel bilden] Wenn man $N$ hat, nimmt man daraus $k$ "ahnliche User aus $N$, die das Item $i$ bewertet haben. F"ur alle User in $N$, multipliziert man das Rating des entsprechenden Users mit dem Wert seiner "Ahnlichkeit zu $u$. Dadurch werden Ratings von User, die sehr "ahnlich sind st"arker gewichtet. 
\end{description}

Userbased Collaborative Filtering sucht nach User, die "ahnlich wie der aktive User $u$ sind. Um das Model zu erstellen, werden die vergangene Bewertungen der User verwendet.

Die Technik um "ahnliche User zu finden heisst k- Nearest-Neighbors (kNN). 

\subsection{Informelles Beispiel}
\label{sec:example}

Bespielsweise m"ochte man die Bewertung von User Peter f"ur den Film "Titanic", den Peter noch nicht bewertet hat, vorhersagen. Man sucht nach anderen Usern, die Filme "ahnlich bewerten wie Peter. Dazu beschaftt man sich f"ur jeden anderen User eine Liste aller Filme, die Peter und andere User bewertet haben. So findet man heraus welche $k$ User Peter am "ahnlichsten sind. Das ist seine Nachbarschaft $N$. Um vorherzuagen welche Bewertung Peter Titanic gibt, verwendet man die Bewertungen der User in $N$. Wenn "ahnliche User Titanic eine hohe Bewertung geben wird eine hohe Bewertung von Peter vorhergesagt. Die Bewertung f"ur Titanic con Usern die Peter sehr "ahnlich sind haben ein gr"osseres Gewicht als die Bewertungen von Usern die Peter un"ahnlich sind.


\subsection{Nachbarschaft bestimmen}
\label{sec:neigborhood}

Dieser Abschnitt beschreibt, wie die Nachbarschaft  $N \subseteq U$ eines einzelnen Users $u$ erstellt wird. Eine Nachbarschaft ist eine sortierte Liste von Usern. Sie ist nach der "Ahnlichkeit $sim(u,v)$ sortiert.  Der Wert $sim(u,v)$ ist ein Model der "Ahnlichkeit zwischen dem aktiven User und einem anderen User $v$. Zuerst wird beschrieben, wie $sim(u,v)$ definiert werden kann.

Es gibt mehrere M"oglichkeiten die "Ahnlichkeit zwischen zwei User zu evaluieren. In diesem Report werden zwei Metriken beschrieben

\begin{itemize}
  \item Pearson Korrelation 
  \item euklidische Distanz
\end{itemize}


Es ist nur m"oglich die "Ahnlichkeit zwischen 2 User zu berechnen, wenn es ein Subset der Items gibt, die beide User bewertet haben. Wenn dieses Subset leer ist, k"onnen die nachfolgenden Methoden nicht angewendet werden. Der Recommender wurde so implementiert, dass User, die keine gemeinsamen Items haben einen A"hnlichkeitswert von 0 haben. Das heisst, dass die Bewertungen dieser User keinen Einfluss auf die berechnung der unbekannten Bewertung haben. 

Listing \ref{lst:shareditems} zeigt, wie sich das Programm eine Liste aller gemeinsamen Items beschafft. Die Funktion \verb|shareditems| gibt nimmt zwei User und eine MultiMap und gibt alle gemeinsamen Items zur"uck. 

\begin{lstlisting}[caption=Implementation von shareditems, label=lst:shareditems]
shareditems :: User -> User -> Multimap User Item -> [Items]
shareditems u1 u2 m = shared (lookup u1 m) (lookup u2 m)
  where shared l1 l2 = [x| x <- l1, y <- l2, x == y]
\end{lstlisting}

\subsubsection{Pearson Korrelation}
\label{sec:pearsoncorrelation}

Gem"ass \cite{jannach11} eignet sich die sogennante Pearson Korrelation gut f"ur Userbased CF. Die Pearsonkorrelation, oder Korrelationskoeffizient ist ein dimensionsloses Mass f"ur den linearen Zusammenhang von zwei Listen. Der Korrelationskoeffizient nimmt Werte zwischen -1 und +1 an. +1 bedeutet, dass die Listen sehr "ahnlich sind. -1 bedeutet dass sie un"ahnlich sind. Bei 0 besteht kein Zusammenhang. Die Pearson Korrelation ist folgendermassen definiert.

\begin{equation}
 sim(u,v) = \frac{cov(X,Y}{\sigma_X \sigma_Y)} 
\end{equation}
oder
\begin{equation}
  \label{eq:pearson}
  sim(u,v)  = \frac{\sum_{i \in I_u \cap I_v}(r_{u,i} - \bar{r}_u)(r_{v,i} - \bar{r}_v)}{\sqrt{\sum_{i \in I_u \cap I_v}( r_{v,i} - \bar{r}_v)^2}\sqrt{\sum_{i \in I_u \cap I_v}( r_{v,i} - \bar{r}_v)^2}}
\end{equation}

Die Pearson Similariy ber"ucksichtig User, die Items konstant tiefer bewerten. Wenn man zwei User die mit den Vektoren (1,2,3,4) und (2,3,4,5) dargestellt werden erhalten die maximale "Ahnlichkeit von 1.

Um die Pearson Korrelation zu berechnen muss man sich zuerst die Liste $I_u \cap I_v$ mit den gemeinsam bewerteten Items beschaffen. Diese Item bildet man auf die Bewertungen der entsprechenden User ab. Listing \ref{lst:item2rating} zeigt die Implementation der Abbildung. Wenn man diese beiden Listen mit Bewertungen hat, kann man die "Ahnlichkeit berechnen.

\begin{lstlisting}[caption=Implementation: Abbildung Items zu Bewertungen, label=lst:item2rating]
import Data.MultiMap
item2rating:: [Item] -> Multimap Item Double -> [Double]
item2rating is m = map (\i -> findWithDefault 0 i m) is
\end{lstlisting}

Das Paket \verb|Math.Statistics| stellt die Funktion \verb|pearson| zur Verf"ugung um den Korrelationskoeffizenten zu berechnen.

Bei der Verwendung der Pearson Korrelation sind mehrere Schwierigkeiten bei der Evaluation aufgetreten.

\begin{description}
\item[Hohe "Ahnlichkeit bei wenig Items] Die Berechnung Pearson Korrelation zwischen zwei Usern, die nur ein Item gemeinsam bewertet haben f""uhrt zu relativ hohen "Ahnlichkeitswerten, obwohl zwei User die nur ein gemeinsames Item haben eher un"ahnlich sind.
\item[Abweichung 0] Wenn die Bewertungen eines Users f"ur alle gemeinsame Items  $I_u \cap I_v$ gleich sind f"uhrt das zu einer Standardabweichung von 0. Da in diesem Fall der Nenner in Gleichung \ref{eq:pearson} wird, ist der Korrelationskoeffizient nicht definiert, wenn ein User alle gemeinsamen Items gleich Bewertet.
\item[Nur ein gemeinsamens Item] Wenn  $I_u \cap I_v$ nur ein gemeinsames Item enth"alt ist die Standardabweichung immer 0.
\end{description}

In einem ersten Versuch wurden, die oben genannten Probleme durch entsprechende Fallunterscheidung in der Implementation abgefangen. Listing \ref{lst:similarity} zeigt die Implementation.

\begin{lstlisting}[caption=Similarity, label=lst:similarity]
import Math.Statistics

similarity :: [Double] -> [Double] -> Double
similarity r1 r2
  | (length r1) < 2 = 0
  | (length r2) < 2 = 0
  | stddev r1 == 0.0 = 0
  | stddev r2 == 0.0 = 0
  |  otherwise = MS.pearson r1 r2

\end{lstlisting}

Wenn die Varianz der betrachteten Bewertungen 0 ist, gibt diese Implementation einen "Ahnlichkeitswert von 0 zur"uck. 0 bedeutet, dass es keine Korrelation zwischen den beiden Usern gibt.

Diese Implementation der "Ahnlichkeit hat zu einem MAE von 0.830 gef"uhrt. Das ist ein gr"osserer MAE als man mit dem unpers"onlichen Recommender, der Gleichung \ref{eq:baseline} anwendet aus Abschnitt \ref{sec:simple}, erreicht. Das Resulat ist also noch unbefriedigend.


\subsubsection{Optimierte Pearson Korrelation}
\label{sec:optpearson}

Ein Grund f"ur die Probleme ist, dass der definierte Korrelationskoeffizient aus Gleichung \ref{eq:pearson} nur die Bewertungen der gemeinsamen Items  $I_u \cap I_v$ bei der Berechnung der "Ahnlichkeit ber"ucksichtigt. F"ur die Standardabweichugen der Bewertungen der User macht es aber mehr Sinn alle Bewertungen des Users zu ber"ucksichtigen. Statt 

\begin{equation}
  \label{eq:naiv}
  \sqrt{\sum_{i \in I_u \cap I_v}( r_{v,i} - \bar{r}_v)^2}
\end{equation}

macht es mehr sind das Mittel alle $b_u$ (siehe Abschnitt \ref{sec:simple}, Gleichung \ref{eq:baseline}) aller Bewertungen des User $u$ zu verwenden. Also

\begin{equation}
  \label{eq:naiv}
  \sqrt{\sum_{i \in I_u \cap I_v}( r_{v,i} - b_u)^2}
\end{equation}

In die Gleichung \ref{eq:pearson} eingesetzt, berechnet sich die "Ahnlichkeit folgendermassen:

\begin{equation}
  \label{eq:advanced}
  sim(u,v)  = \frac{\sum_{i \in I_u \cap I_v}(r_{u,i} - b_u)(r_{v,i} - b_v)}{\sqrt{\sum_{i \in I_u \cap I_v}( r_{v,i} - b_u)^2}\sqrt{\sum_{i \in I_u \cap I_v}( r_{v,i} - b_v)^2}}
\end{equation}

Da statt der Standardabweichung $b_u$ verwendet wird kann nicht mehr die \verb|pearson|-Funktion aus dem Statistik Paket verwendet werden. Die "Ahnlichkeitsfunktion wurde anpasst implementiert.

\subsubsection{Euklidische Distanz}
\label{sec:euclid}

Der Pearson Korrelationkoeffizient ist nicht definiert ist, wenn die Varianz der betrachteten Bewertungen 0 ist. Deshalb wurde eine alternative "Ahnlichkeitmetrik untersucht. \cite{segaran} schl"agt vor die euklidische Distanzmetrix f"ur Usebased Collaborative Filtering zu verwenden. Die euklidische Distanz ist auch definiert wenn die Varianz 0 ist.

Jeder User wird als Vektor dargestellt. Die Bewertungen, die der User gemacht hat, sind die Elemente des Vektor. Die euklidische Distanz berechnet den geometischen Abstand der Vektoren. F"ur zwei User $u$ und $v$ mit $n$ gemeinsamen Items, wird die $sim(u,v)$ wie folgt berechnet:

\begin{equation}
  \label{eq:euclid}
 sim(u,v) = \sum_i^n (u_i - v_i )^2
\end{equation}

Die euklidische Distanz ber"ucksichtigt nicht, dass bestimmte User permanent h"ohere Wertungen geben.

\subsection{Unbekannte Bewertung absch"atzen}
\label{sec:compp}

In diesem Abschnitt wird beschrieben, wie die Nachbarschaft von Abschnitt \ref{sec:neigborhood} genutzt werden kann, um eine unbekannte Bewertung des aktiven User $u$ f"ur ein Item $i$ vorauszusagen.

\subsubsection{Nachbarschaft generieren}
\label{sec:generate}

M"ochte man zu User $u$ und Item $i$ eine Bewertung vorhersagen, ben"otigt man eine geeignete Nachbarschaft $N \subseteq U$. User in $N$ m"ussen das Item $i$ bewertet haben und dem User $u$ m"oglichst "ahnlich sein.

Zuerst beschafft man sich die komplette Nachbarschaft eines User. Aus dieser Nachbarschaft filtert man diejenigen User, die das Item $i$ bewertet haben. Die gefilterte Liste wird aufsteigend nach der "Ahnlichkeit $sim(u,v)$ sortiert. Diese Liste entspricht $N$. 

In Listing \ref{lst:neighborhood} wird gezeigt, wie die Abfrage in Haskell implementiert wurde. Die Funktion \verb|neighborhood| nimmt neben dem User $u$ und dem Item $i$ noch eine Ganzahl $k$ als Paramater. $k$ bestimmt die Gr"osse der Nachbarschaft, die f"ur die Vorhersage verwendet wird.

\begin{lstlisting}[caption=Funktion um die Nachbarschaft f"ur ein User und ein Item zu generieren, label=lst:neighborhood]
import Data.MultiMap
neihborhood :: User
            -> Item
            -> Int
            -> MultiMap User [(Similarity, User)]
            -> [User]
neihborhood u i k m = take k (reverse (sort onlyItem i u ))
  where onlyItem i = filter (hasRated i) allneighbors
        allneighbors = lookup u m
\end{lstlisting}

Bei der Berechnung von $p_{u,i}$ kann die Gr"osse der Nachbarschaft $N$ frei gew"ahlt werden. Die Gr"osse der Nachbarschaft ist definiert als Parameter $k$. Wenn $k$ zu klein ist, werden nur wenige Bewertungen von anderen User zu Berechnung verwendet. Da $p_{u,i}$ in diesem Fall nur von wenigen anderen Usern abh"angig ist, ist es anf"allig f"ur Ausreisser. Wenn $k$ zu gross gew"ahlt wird, werden auch die Bewertungen der User die dem aktiven User un"ahnlich sind ber"ucksichtigt. Diese Bewertungen sind f"ur den aktiven User nicht interessant. 

\subsubsection{Unbekannte Bewertung berechnen}
\label{sec:predict}

Wenn man $N$ generiert hat, kann man damit eine unbekannte Bewertung $p_{u,i}$ absch"atzen. Jeden User $u' \in N$ bildet man auf das Produkt der "Ahnlichkeit $sim(u,u')$ mit der Bewertung $r_{u',i}$ ab. Die Werte der Abbildung werden summiert. Damit man eine Zahl zwischen 1 und 5 erh"alt wird diese Summe normiert. Die Summe wird mit der Summe aller "Ahnlichkeitswerte $\sum_{u' \in N}{|s(u,u')|}$ normiert. Gleichung \ref{eq:computeprediction} beschreibt die Berechnung von $p_{u,i}$ formel.

\begin{equation}
  \label{eq:computeprediction}
  p_{u,i} = \frac{\sum_{u' \in N}{sim(u,u') r_{u',i}}}{\sum_{u' \in N}{|s(u,u')|}}
\end{equation}

Die Implementation der Gleichung \ref{eq:computeprediction} ist in Listing \ref{lst:knnpredict} dargestellt. Die Funktion \verb|predict| nimmt User, Item, Model und $k$ als Argument. Das Model enth"alt die vorberechneten Nachbarschaften. Die Funktion \verb|knn| greift darauf zu und stellt die Nachbarschaft f"ur den aktiven User und dem gew"unschten Item zusammen.

\begin{lstlisting}[caption=Berechnung von $p_{u,i}$, label=lst:knnpredict]
  predict :: User
   -> Item
   -> Model
   -> Int
   -> Double
predict u i k m = rating / normalization
  where n = neighborhood u i k m
        normalization = sum [ s | (s,_,_) <- u i k m]
        rating = sum [s * r | (s, r, u) <- u i k m]
\end{lstlisting}

Bei der Evaluation hat sich herausgestellt, dass die Anwedung von Gleichung \ref{eq:computeprediction} zur Absch"atzung von unbekannten Bewertungen schlechte Resultate liefert. Die Methode erreichte einen MAE von 1.0514. 

Die Methode kann optimiert werden, indem man nur die Abweichung aller der Bewertung von einem User mittel ber"ucksichtig. Die Abweichung ist
\begin{equation}
  \label{eq:dev2}
r_{u',i} - \bar{r_{u'}}
\end{equation}

Wenn man das in die Gleichung \ref{eq:computeprediction}einsetzt erh"alt man

\begin{equation}
  \label{eq:optcomputeprediction}
  p_{u,i} = \frac{\sum_{u' \in N}{sim(u,u') (r_{u',i} - \bar{r_{u'}})}}{\sum_{u' \in N}{|s(u,u')|}}
\end{equation}

\subsection{Resultate}
\label{sec:userbasedresults}

Userbased Collaborative Filtering nimmt drei Parameter.
\begin{itemize}
\item "Ahnlichkeitsmetrik
\item Formel f"ur Berechnung unbekannter Bewertungen $p_{i,u}$.
\item Nachbarschaftsgr"osse $k$
\end{itemize}

Mithilfe der Evaluation k"onnen experimentell diejenigen Parameter gefunden werden, die zum geringsten MAE f"uhren. In diesem Abschnitt werden die Resultate der Experimente pr"asentiert. 

\subsubsection{"Ahnlichkeitsmetrik}
\label{sec:simresults}

In Abschnitt \ref{sec:neigborhood} wurden drei "Ahnlichkeitsmetriken vorgestellt:

\begin{itemize}
\item Pearson Korrelation
\item Optimierte Pearson Korrelation
\item Euklidische Distanz
\end{itemize}

F"ur jede "Ahnlichkeitmetrik wurde ein Userbased-Model mit dem Trainingset erstellt. Diese wurden mit dem Testset evaluiert. Der Vegleich der "Ahnlichkeitmetriken wurde mit einer Nachbarschaftsgr"osse $k$ von 5 erstellt und $p_{i,u}$ wurde mit der Formel \ref{eq:optcomputeprediction} berechnet. Abbildung \ref{fig:comparesim} zeigt die Resultate der Experimente.

\begin{figure}
\begin{tikzpicture}
  \begin{axis}[
    xbar, xmin=0.7, xmax=0.95,
    height=6cm,width=10cm, enlarge y limits=0.5,
    symbolic y coords = {Euklidische Distanz,Pearson Korr.,Opt. Pearson Korr.},
    xlabel={Mean Absolute Error},
    ytick = data,
    nodes near coords, nodes near coords align={horizontal},
    ]
    \addplot coordinates {(0.872,Euklidische Distanz) (0.831,Pearson Korr.) (0.718,Opt. Pearson Korr.)};
  \end{axis}
\end{tikzpicture}
\centering
\label{fig:comparesim}
\caption{Vergleich der "Ahnlichkeitsmetriken euklidische Distanz und Pearson Korrelation}
\end{figure}

Der Vergleich der "Ahnlichkeitsmetriken zeigt, dass der Userbased Collaborative Filtering Algorithmus den kleinsten Fehler beim berechnen von unbekannten Bewertungen mit dem optimierten Korrelationskoeffizienten macht.

\subsubsection{Berechnung unbekannter Bewertungen}
\label{sec:eqpredictresults}

Eine unbekannte Bewertung kann auf mehrere Arten berechnet werden. In Abschnitt \ref{sec:predict} wurden die Formeln \ref{eq:computeprediction} und \ref{eq:optcomputeprediction} zur Berechnung  von $p_{u,i}$ beschrieben. Bei der ersten Variante wird das Produkt von "Ahnlichkeit und Bewertung berechnet. Bei der zweiten Variante nur das Produkt zwischen Abweichung und "Ahnlichkeit. Beide Formeln wurden mit den Testdaten evaluiert. Wie in Abbildung \ref{fig:predicteq} ersichtlich hat diese "Anderung der Berechnung einen starken Einfluss auf den MAE. Die Messungen wurden mit einer Nachbarschaftsgr"osse von 20 und dem Pearson Korrelationskoeffizienten durchgef"uhrt.

\begin{figure}
\begin{tikzpicture}
  \begin{axis}[
    xbar, xmin=0.7, xmax=1.1,
    height=6cm,width=10cm, enlarge y limits=0.5,
    symbolic y coords = {Bewertung,Abweichung,},
    xlabel={Mean Absolute Error},
    ytick = data,
    nodes near coords, nodes near coords align={horizontal},
    ]
    \addplot coordinates {(1.0514,Bewertung) (0.841,Abweichung)};
  \end{axis}
\end{tikzpicture}
\centering
\label{fig:predicteq}
\caption{Vergleich der Berechnungmethoden f"ur $p_{u,i}$}
\end{figure}

\subsubsection{Gr"osse der Nachbarschaft}
\label{sec:neighborhoodsize}

Die Gr"osse der Nachbarschaft $k$ hat grossen Einfluss auf die Qualit"at des Recommender. Um den besten Wert f"ur $k$ herauszufinden wurden mehrere Testl"aufe mit unterschiedlichem $k$ ausgef"uhrt.

\begin{figure}
  \centering
\begin{tikzpicture}
  \begin{axis}[
    title=Sensitiv"at der Nachbarschaftsgr"osse,
    xlabel=Anzahl Nachbarn,
    ylabel=MAE,
]
\addplot table {kdata.dat};
  \end{axis}
\end{tikzpicture}
\label{fig:nrofneighbors}
\caption{Vergleich der "Ahnlichkeitsmetriken euklidische Distanz und Pearson Korrelation}
\end{figure}

Abbildung \ref{fig:nrofneighbors} zeigt den Mean Absolute Error in Abh"angigkeit der Nachbarschaftsgr"osse $k$. F"ur das gegebene Testset funktioniert eine Nachbarschaftsgr"osse von 10 am besten.

\begin{figure}
  \centering
\begin{tikzpicture}
  \begin{axis}[
    xbar, xmin=0.6,
    height=4.5cm, width=12cm, enlarge y limits=0.5,
    symbolic y coords = {Userbased CF,$b_{ui}$},
    xlabel={MeanAbsoluteError},
    ytick = data,
    nodes near coords, nodes near coords align={horizontal},
    ]
    \addplot coordinates {(0.66,Userbased CF) (0.861,$b_{ui}$)};
  \end{axis}
\end{tikzpicture}
\label{fig:uuvsbui}
\caption{Vergleich von Userbased CF mit unpers"onlichen Empfehlungen}
\end{figure}

F"ur den Vergleich von Abbildung \ref{fig:uuvsbui} wurde der Userbased Algorithmus mit einer Nachbarschaftsgr"osse von 30 und mit der optimierter Pearson Korrelation Metrik ausgef"uhrt. 

Wie man Abbildung \ref{fig:uuvsbui} entnehmen, kann bringt Userbased Collaborative Filtering einen qualitativen Vorteil im Vergleich zur unpers"onlichen Bewertungsberechnung \ref{eq:bui}. Der Algorithmus ist intuitiv und relative einfach zu implementieren. Da er nur zwei Paramter hat ("Ahnlichkeitsmetrik, Nachbarschaftsgr"osse) kann man den Algorithmus einfach einsetzen. Wenn man gute Map Implementationen zur Verf"ugung hat, kann eine Bewertung in vern"unftiger Zeit abgesch"atzt werden.
Die Optimierung der "Ahnlichkeitmetrik hat die Qualit"at des Recommender stark verbessert. Die Ber"ucksichtigung der User Tendenzen hat den Fehler ebenfalls reduziert.

\section{Matrixfaktorisierung}
\label{sec:matrixfactorization}

Wie bereit in Abschnitt \ref{sec:cfmodels} erw"ahnt gibt es neben den kNN-Methoden noch sogenannte Latent Factor Modelle. Latent Factor Modelle versuchen die Items und die User zu charakterisieren. 

Man geht davon aus Users und Items sogenannte Latent Factors haben. Das heisst ein User hat zum Beispiel bestimmte Preferenzen. Diese Preferenzen kann mit einem Vektor repr"asentiert werden. Jedes Element sagt aus, ob dem User eine bestimmte Eigenschaft wichtig ist oder nicht. 


\subsection{Intuition}
\label{sec:intuition}

Ein User der Action mag aber keine Romanze k"onnte zum Beispiel durch folgenden Vektor repr"asentiert werden.

\begin{equation}
  \label{eq:vektor}
  p_u = \left(
  \begin{array}[c]{c}
    5 \\
    1 
  \end{array}
\right)
\end{equation}

Die 5 repr"asentiert Action und die 1 repr"asentiert die den Romantik Preferenz.

 Ein Film kann ebenfalls nach den selben Dimensionen bewertet werden. Ein Vektor kann beschreiben wie actiongeladen oder wie romantisch ein Film ist. Die Bewertung ist das Skalarprodukt der Preferenzen des Users und den Eigenschaften des Items. Das heisst die Bewertung ist maximal, wenn die Latent Factor Vektoren von User $p_u$ und Item $p_i$ "ubereinstimmen.

Beim Latent Factor Ansatz ist es nicht relevant, welche Bedeutung die Elemente in den Featurevektoren haben. Es geht nur darum die Muster zu finden. Matrixfaktorierung generiert Vektoren f"ur Eigenschaften, die wir gar nicht interpretieren k"onnen.

Abbildung \ref{fig:moviedimension} veranschaulicht die Idee. In Abbildung \ref{fig:moviedimension} werden Filme als Objekte in einem Diagramm mit zwei Dimensionen dargestellt. In diesem Beispiel sind es die Dimensionen Action und Romantik. Die Eigenschaften werden als Zahlen von 0 bis 1 ausgedr"uckt. Rambo 4 ist beispielweise ein Film, der durch keine Romantik und viel Action charakterisiert wrden kann.

\begin{figure}
\centering
\begin{tikzpicture}[inner sep=5pt]
\begin{axis}[
  nodes near coords,
  enlargelimits=0.5,
  xlabel= Action,
  ylabel=Romantik,
  x
  ]
\addplot+[only marks,
point meta=explicit symbolic]
coordinates {
(0.5,0.3) [Braveheart]
(0.1,0.9) [Die Farbe Lila]
(0.6,0.7) [Lord of the Rings]
(0.1,0.1) [99 Francs]
(0.9,0.0) [Rambo 4]
};
\end{axis}
\end{tikzpicture}
\label{fig:moviedimension}
\end{figure}


\subsection{Matrixfaktorisierung Model}
\label{sec:matrixfactorizationmodel}

Das Model der Matrixfaktorisierung weist jedem User und jedem Item einen Latent Factor Vektor der L"ange $f$ zu. Jedes Item kann durch einen Vektor $q_i \in \mathbb{R}^f$ repr"asentiert werden und jeder User kann durch einen Vektor $p_u \in \mathbb{R}^f$ repr"asentiert werden. Wenn man die Bewertung von Item $i$ f"ur User $u$ absch"atzen m"ochte, kann man das Vektorprodukt von $q_i$ und $p_u$ berechnen.

\begin{equation}
  \label{eq:rui}
  \hat{r_{ui}} = q_i^T p_u
\end{equation}

$\hat{r_{ui}}$ bescheibt wie gut die Preferenzen des Users $u$ mit den Eigenschaften des Items $i$ "ubereinstimmen. Das nennt man die Interaktion zwischen User und Item.

In Haskell kann die Gleichung \ref{eq:rui} einfach implementiert werden. Das Modul \verb|Data.Vector| aus dem Package \verb|vector| stellt die Funktion \verb|vdot| zur Verf"ugung. Die Implemantation ist in Listing \ref{lst:rui} dargestellt.

\begin{lstlisting}[caption=Implementation der Vorhersage, label=lst:rui]
import Data.Vector
rui:: Vector -> Vector -> Double
rui qi pu = vdot qi pu
\end{lstlisting}

\subsection{Dimensions Reduktion}
\label{sec:dimred}

Repr"asentiert man die User-Item Interaktion mit der Ratingmatix ben"otigt man 

\begin{equation}
  \label{eq:dimre}
  1682 * 943 = 1586126
\end{equation}

Eintr"age. Diese 1,5M Eintr"age m"ussen alle berechnet werden. Wenn man die Interaktion zwischen User und Item mit Latent Factor Vektoren mit 40 Faktoren repr"asentiert ben"otigt man 

\begin{equation}
  \label{eq:dimred}
  40(1682*943) = 105000
\end{equation}

Eintr"age. Das sind mehr als 15-mal weniger. Mit den Latent Factor Vektoren kann man die Interaktion zwischen User und Item kompakter darstellen.

\subsection{Optimierungsproblem}
\label{sec:optim}

Bei Matrixfaktorisierung geht es darum, die Latent Factor Vektoren $q_i$ und $p_u$ f"ur jedes Item und jeden User abzusch"atzen. Sobald eine gute Absch"atzung der Latent Factor Vektoren vorliegt, kann mit Hifle von Gleichung \ref{eq:rui} eine Vorhersage der Bewertung eines Users f"ur ein Item berechnen werden. Das Recommenderproblem wird auf das Optimierungsproblem, geeignete  $q_i$ und $p_u$ Vektoren zu finden, reduziert

Die Latent Faktor Vektoren $q_i$ und $p_u$ k"onnen mit Hilfe der vorhandenen Bewertungen approximiert werden. Sie werden also von den Trainingsdaten abgeleitet. Mit den vorhandenen Bewertungen kann man berechnen, wie gut die angenommenen Latent Factor Vektoren sind. F"ur eine vorhandene Bewertung $r_{ui}$ berechnet man den Fehler $e_{ui}$ wie folgt:

\begin{equation}
  \label{eq:error}
  e_{ui} = r_{ui} - q_i^T p_u
\end{equation}

$r_{ui}$ ist eine Zahl von 1 bis 5, die die Bewertung von User $u$ f"ur Item $i$ repr"asentiert. $e_{ui}$ nennt man auch die Residuen.

Ziel des Recommendersystems ist es $q_i \in \mathbb{R}^f$ und $p_u \mathbb{R}^f$ so zu w"ahlen, dass die Summe aller Fehler $e_{ui}$ minimal wird. Die Berechnung der Gleichung \ref{eq:error} f"uhrt man f"ur alle gegebenen Bewertungen durch und berechnet die Summme der Residuen.

\begin{equation}
\label{eq:errorsum}
  \sum_{(u,i) \in \kappa} (r_{ui} - q_i^T p_u)
\end{equation}

$\kappa$ ist die Menge aller $(u,i)$-Paare f"ur eine explizite Bewertung gemacht wurde. Diese Menge entspricht dem Trainingset.

Wenn man Vektoren $q_i$ und $p_u$ findet, bei denn die Summe in Formel \ref{eq:errorsum} minimal, st hat man eine Absch"atzung der Eigenschaften aller Users und Items. Bei der Methode Matrixfaktorierung geht es also darum folgendes Optimierungsproblem zu l"osen.

\begin{equation}
  \label{eq:objective}
  \min_{q*,p*} \sum_{(u,i) \in \kappa} (r_{ui} - q_i^T p_u)
\end{equation}

 Die Bewertungen k"onnen als Item-User Matrix dargestellt werden. In dieser Matrix sind die meisten Zellen leer, da es nicht zu allen Item User Kombinationen Bewertungen gibt. 


\subsubsection{Regularisierung}
\label{sec:regularization}

Wenn man Gleichung \ref{eq:objective} minimiert, werden $q_i$ und $p_u$ so gew"ahlt, dass der Fehler f"ur die vorher bekannten Werte minimiert wird. Das ist aber nicht gew"unschte Verhalten. Man m"ochte die Featurevektoren mit dem Trainingsset berechnen und sie sp"ater auf ein unbekanntes Set anwenden. Die Gleichung \ref{eq:objective} bestimmt Parameter, die sich auf das Trainingsset spezialisieren. Die Optmierung soll also generalisiert werden.

 Dieses Verhalten wird mit einem Regularisierungterm erreicht. Der Regularisierungsterm f"uhrt dazu, dass die Elemente von $q_i$ und $p_u$ nicht zu gross werden. Die Konstante $\lambda$ kontrolliert wie stark die Gleichung \ref{eq:objective} regularisiert wird \cite{koren2009}.

\begin{equation}
  \label{eq:optimization}
    r_{ui} - q_i^T p_u + \lambda (\lVert q \rVert^2 + \lVert p \lVert ^2)
\end{equation}

\subsubsection{Kostenfunktion}
\label{sec:opt}

Aus der Gleichung \ref{eq:optimization} kann man eine sogenannte Kostenfunktion oder Objectivefunction herleiten. Die Optmierungsverfahren ben"otigen eine Kostenfunktion $J$. Diese Funktion soll die Latent Faktor Vektoren $q_i$ und $p_u$ als Argument nehmen und die Summe der Residuen zur"uckgeben. Umso kleiner diese Summe ist, umso besser sind die Parameter gew"ahlt. Die Kostenfunktion sieht folgendermassen aus:

\begin{equation}
  \label{eq:costfunction}
  J(q_1, \dots , q_n, p_1, \dots, p_m) =  (r_{ui} - q_i^T p_u)^2 + \lambda (\lVert q \rVert^2 + \lVert p \lVert ^2)
\end{equation}

$J$ nimmt f"ur jeden User $u$ und jedes Item $i$ einen Latent Faktor Vektor $q_i \in \mathbb{R}^f$ und $p_u \mathbb{R}^f$.

\subsubsection{Initialisierung}
\label{sec:init}

Um Kostenfunktion $J$ die Kostenfunktion zu optimieren, ben"otigt man einen Startpunkt. F"ur das Optimierungproblem \label{eq:objective} haben sich Vektoren mit kleinen Werten bew"ahrt \cite{Takacs08}. In diesem Projekt wurden die Latent Faktor Vektoren mit 0.1 in allen Elemente initialisiert.

Eine weitere M"oglichkeit die Featurevektoren zu initialisieren ist die leeren Zellen Ratingmatrix auszuf"ullen. M"ogliche Werte f"ur die Zellen liefern die Formeln der unpers"onliche Empfehlungstechniken aus Abschnitt \ref{sec:simple}. F"ur jede Zelle, die keine Bewertung enth"alt wird

\begin{equation}
  \label{eq:mu2}
    b_{u,i} = \mu + b_u + b_i
\end{equation}

ausrechnet.

Aus dieser vorberechneten Ratingmatrix kann man die Latent Faktor Vektoren mit einer Singul"arwertzerlegung gewinnen.

In diesem Projekt wurden die Latent Faktor Vektoren mit 0.1 in allen Elemente initialisiert.

\subsubsection{Einfacher Gradientenabstieg}
\label{sec:gradientdescent}
 
Um das Minimum zu finden kann beispielsweise das Verfahren Gradientenabstieg angewendet werden. Dazu wird die Kostenfunktion $J$ nach $q_i$ und nach $p_u$ abgeleitet. F"ur $q_i$ lautet die Ableitung:

\begin{equation}
  \label{eq:decx}
  \frac{ \partial J }{ \partial q_i } = \sum (q_i^T p_j - r) p_j + \lambda q_i
\end{equation}

Und f"ur die $p_i$ wird folgendermassen abgeleitet:

\begin{equation}
  \label{eq:dectheta}
  \frac{ \partial J }{ \partial p_i } = \sum (q_i^T p_j - r) q_j + \lambda p_i
\end{equation}

Es hat sich herausgestellt, dass das Verfahren des Gradientenabstiegs f"ur eine Ratingmatrix mit den Dimensionen 1682 x 943 nicht skaliert. Sobald man mehrere Iterationen durchf"uhrt dauert das Verfahren mehrere Stunden. Und wenn man zu wenige Iteration durchf"uhrt, werden die Paramter nicht befriedigend optimiert. Ein Durchlauf mit 10 Iterationen dauerte auf der Evaluationsplattform 44 Minuten und f"uhrte zu einem MAE von 1.0235. Das ist ein schlechtere Resultat als 

Die Berechnung der partiellen Ableitungen \label{eq:decx} und \label{eq:dectheta} ist aufwendig. F"ur jeden Parameter von $J$ f"ur jede Dimension der Latent Faktor Vektoren muss "uber das ganze Trainingsset iteriert werden.

\subsection{Funk's stochastischer Gradientabstieg}
\label{sec:funksvd}

Statt des einfachen Gradient Descent wurde eine Variante der Gradient Descent Methode implementiert. Die Methode wurde von Simon Funk beschrieben \cite{funk}. Die Implementation basiert auf dieser Beschreibung.

Funk's Stochastischer Gradientenabstieg iteriert durch alle User-Item Paare des Trainingsets. Mit den initialen Latent Factor Vektoren $q_i$ und $p_u$ wird f"ur jede Bewertung im Trainingset der Fehler berechnet. Es ist einfach die Item-User Paare des Trainingsets abzufragen. Listing \ref{lst:trainingcases} zeigt die Implementation.

\begin{lstlisting}[caption=Abfrage des Trainingsets,label=lst:trainingcases]
import qualified Data.Matrix as M  
trainingcases :: M.Matrix Double -> [(Int, Int)]
trainingcases y = [(x2, x1) | x1 <- [1..(M.ncols y)], 
         x2 <- [1..(M.nrows y)],
         (M.getElem x2 x1 y) /= 0.0 ]
\end{lstlisting}

\begin{equation}
  \label{eq:error1}
  e_{ui} = r_{ui} - q_i^T p_u
\end{equation}

Wenn man diese Gleichungen partiell nach $q_i$ und $p_u$ ableitet, erh"alt man folgende Formeln

\begin{equation}
  \label{eq:devqi}
  (r_{ui} - q_i^T p_u) * p_u =  e_{ui} * p_u
\end{equation}

\begin{equation}
  \label{eq:devpu}
    (r_{ui} - q_i^T p_u) * q_i =  e_{ui} * q_i
\end{equation}

Bei der Methode des stochastischen Gradientenabstiegs passt man jeden Parameter in der Richtung des Fehlers an. Die Richtungen der Fehler sind die Ableitungen aus Gleichung \ref{eq:devqi} und \ref{eq:devpu}. Die Parameter werden also wie folgt angepasst:

\begin{equation}
  \label{eq:assignpi}
 q_i \leftarrow q_i + \alpha (e_{ui} * p_u)
\end{equation}

und

\begin{equation}
  \label{eq:assignqu}
 p_u \leftarrow p_u + \alpha (e_{ui} * q_i)
\end{equation}

$\alpha$ ist eine Konstante. Sie bestimmt mit welcher schrittweite die Paramter angepasst werden. In Abschnitt \label{sec:results} wird die Optimierung von $\alpha$ beschrieben.

W"ahrend einer Iteration werden die beiden Zuweisungen \ref{eq:assignpi} und \ref{eq:assignqu} durchgef"uhrt. Bei jeder Iteration wird $e_{ui}$ neu berechnet. Da bei einer Zuweisung werden $q_i$ und $p_u$ zur Berechnung verwendet. Die Latent Faktor Vektoren der User und die Latent Faktor Vektoren der Items sind also miteinander gekoppelt und voneinander abh"angig.

Im Gegensatz zum Optmierungsverfahren "einfacher Gradientenabstieg" aus Abschnitt \ref{sec:gradientdescent} muss bei einer Iteration nicht durch das gesamte Trainingsset iteriert werden. Dadurch kann die Optimierung schneller ausgef"uhrt werden.

\subsubsection{Regularisierung}
\label{sec:regularization2}

In Abschnitt \ref{sec:regularization} wurde bereits beschrieben, dass es n"otig ist das Optimierungsverfahren zu Regularisieren. Deshalb werden die Zuweisungen \ref{eq:assignpi} und \ref{eq:assignqu} mit einem Regularisierungsterm erweitert.

\begin{equation}
  \label{eq:assign2}
  q_i \leftarrow q_i + \alpha (e_{iu} p_u + \lambda q_i)
\end{equation}

\begin{equation}
  \label{eq:assign3}
    p_u \leftarrow p_u + \alpha (e_{iu} q_iu + \lambda p_u)
\end{equation}

$\lambda$ ist eine Konstante. Sie steuert die Regularisierung. 

\subsubsection{Implementation}
\label{sec:sgdimpl}

Die Berechnung der eines einzelnen Featurevektors kann in Haskell einfach implementiert werden. Listing \ref{lst:step} zeigt die Implementation. Das Modul \verb|Data.Vector| stellt den Typ \verb|Vector| zur Verf"ugung. Dieser implementiert die Operationen \verb|(Num a => a -> Vector a -> Vector a| und \verb|(+)::(Num a) => Vector a -> Vector a|.

\begin{lstlisting}[caption=Berechnung eines Featurevektors, label={lst:step}]
import Data.Vector 
newqi :: Vector Double
  -> Vector Double
  -> Double
  -> Vector Double
newqi qi pu e = qi + alpha (e * pu - (lambda * pi))
\end{lstlisting}

Da die Datenstrukturen in Haskell immutable sind, k"onnen die Latent Faktor Vektoren $q_i$ und $p_u$ beim Updateschritt nicht einfach durch die neuen Werte ausgetauscht werden. Die Datenstruktur, die die Vektoren zusammenfasst, muss bei jedem Updateschritt neu erstellt werden. Dieser Umstand hat bei den ersten Implementation zur Lauftzeit oft eine "Out of Memory Exception" ausgel"ost. Das Problem konnte behoben werden, indem Maps statt Matrizen eingeseztzt werden. Die Maps werden bei jeder Iteration neu aufgebaut. Das heisst, es werden keine Update auf die Datenstruktur ausgef"uhrt sondern nur Inserts. Diese k"onnen in O(log n) ausgef"uhrt werden und ein Teil alten Datenstruktur kann wiederverwendet werden.

\begin{lstlisting}[caption=Implementation Funk SGD, label=lst:sgd] 
train :: Features
      -> (Int,Int) 
      -> M.Matrix Double 
      -> Features
train (x, theta) (i, u) y
  = (updateRow i newqi x, updateRow u newpu theta)
  where newqi = newqi oldqi oldpu error
        newpu = newpu oldpu oldqi error
        oldqi = M.lookup i 1 x
        oldpu = M.lookup u 1 theta
        error = eui2 (rui (i,u) y) oldqi oldpu  
\end{lstlisting}

\subsection{Resultate}
\label{sec:matrixfactorresults}
In diesem Abschnitt wird die Optimierung der Paramater der Matrixfaktorisierung durch Kreuzvalidierung beschrieben und es werden die Resultate der Evaluierung der Matrixfaktorisierungsmethode pr"asentiert. 

Matrixfaktorisierung dem stochastischen Gradiendenabgieg-Optmierungsverfahren  nimmt vier Parameter.
\begin{itemize}
\item Anzahl Iterationen
\item Anzahl der Features $f$ der Latent Faktor Vektoren
\item Schrittweite des Gradientenabstieg $alpha$
\item Regularisierungskonstante $\lambda$
\end{itemize}

F"ur jeden Parameter wurde ein Experiment durchgef"uhrt.

\subsubsection{Anzahl Iterationen}

\begin{figure}
  \centering
\begin{tikzpicture}
  \begin{axis}[
    title=Minimierung von $J$,
    xlabel=Anzahl Iteration,
]
\addplot table {it.dat};
  \end{axis}
\end{tikzpicture}

\end{figure}


\subsubsection{Anzahl Features}

Die Anzahl Features $f$ bestimmt viele Features die Latent Faktor Vektoren $q_i$ und $p_u$ haben.

Abbildung \ref{fig:lambda} zeigt die Kreuzvalidierung f"ur den Paramter $f$. Bei dieser Evaluation wurde die Anzahl Iterationen auf 20 gesetzt und $\alpha$ auf 0.15. Regularisierung $\lambda$ ist 0.01.

\begin{figure}
  \centering
\begin{tikzpicture}
  \begin{axis}[
    title=Sensitiv"at von $f$,
    xlabel=$f$,
    ylabel=MAE,
]
\addplot table {f.dat};
  \end{axis}
\end{tikzpicture}
\label{fig:lambda}
\caption{Kreuzvaliderierung von $f$ mit $\alpha$ = 0.15 20 Iterationen und $\lambda=0.01$}
\end{figure}

Bei dem gegebenen Datenset haben Latent Faktor Vektoren mit einer Dimension von 5 am besten funktioniert.

\subsubsection{Regularisierungskonstante $\lambda$}

\begin{figure}
  \centering
\begin{tikzpicture}
  \begin{axis}[
    title=Sensitiv"at von $\lambda$,
    xlabel=$lambda$,
    ylabel=MAE,
]
\addplot table {lambda.data};
  \end{axis}
\end{tikzpicture}
\label{fig:lambda}
\caption{Kreuzvaliderierung von $\lambda$ mit $\alpha$ = 0.15 20 Iterationen und $f = 5$}
\end{figure}



\begin{center}
\begin{tabular}{lr}
 Parameter           &  Wert  \\
 Lambda              &  0.02  \\
 Anzahl Iterationen  &    20  \\
 Alpha               &  0.01  \\
\end{tabular}
\end{center}

Abbildung \ref{fig:compare} zeigt einen Vergleich der verschiedenen Recommender Techniken, $b_{ui}$, Userbase Collaborative Filtering und Matrixfaktorisierung.

\begin{figure}
\begin{tikzpicture}
  \begin{axis}[
    xbar, xmin=0,
    width=12cm, enlarge y limits=0.5,
    symbolic y coords = {$b_{ui}$,Userbased,Matrixfaktorisierung},
    xlabel={MeanAbsoluteError},
    ytick = data,
    nodes near coords, nodes near coords align={horizontal},
    ]
    \addplot coordinates {(0.87,$b_{ui}$) (0.84,Userbased) (0.76,Matrixfaktorisierung)};
  \end{axis}
\end{tikzpicture}
\centering
\label{fig:compare}
\caption{}
\end{figure}

Aus der Abbildung ist ersichtlich, dass der Fehler des Recommender bei Matrixfaktorisierung am geringsten ist.

\section{Implementationsdetails}
\label{sec:ram}

Dieser Abschnitt beschreibt Probleme die bei der Implementation aufgetreten sind und m"ogliche L"osungen.

F"ur den Vergleich der beiden Algorithmen Userbased Collaborative Filtering und Matrixfaktorisierung wurden zwei Module geschrieben. Um die Empfehlungen zu Evaluieren wurde ein ausf"uhrbares Programm erstellt. Das ausf"uhrbare Programm liest die Trainingsdaten und Testdaten, erstellt ein Model und berechnet den Mean Absolute Error und schreibt diese auf den Standardoutput.


\subsection{Projekstruktur}
\label{sec:structur}

F"ur dieses Projekt wurden in ein ausf"uhrbares Programm und mehrere Module aufgeteilt. Abbildung \ref{fig:structur} zeigt die Aufteilung.

\begin{figure}
  \centering
      \includegraphics[width=0.5\textwidth]{structur}
  \caption{Projektstruktur}
  \label{fig:structur}
\end{figure}

\begin{description}
\item[evaluaterecommender] Diese Modul ent"halt das ausf"uhrbare Programm. Es nutzt die Module Userbased und Matrixfactorisation um die Evaluation durchzuf"uhren. Der Programmcode f"ur die MAE Berechnung ist ebenfalls in diesem Modul enthalten.
\item[Userbased] Das Modul Userbased enth"alt den User based Collaborative Filtering Recommender und die unpers"onlichen Algorithmen. Das Modul stellt die Funktion \verb|predict| und \verb|model| zur Verf"ugung
\item[Matrixfactorization] Das Modul enth"alt einen Recommender der Matrixfaktorisierung nutzt.
\item[FunkSVD] Der Optimierungalgorithmus von Simon Funk ist in diesem Modul implementiert.
\end{description}

Matrixfactorization enth"alt einen Recommender mit Matrixfaktorisierung. Der Optimierungsalgorithmus Funk's stochatischer Gradientenabstiegt wurde in ein separates 

\subsection{Build System}
\label{sec:cabal}

Um das Projekt zu builden und die Abh"angikeiten aufzul"osen wurde Cabal eingesesetzt. Die verwendete Version ist 1.20.0.2. Cabal ein Paketisierung und Build System f"ur Haskell. In diesem Projekt wurde Cabal eingesetzt, weil Libraries des Package Repository Hackage eingesetzt wurden und Cabal kann Abh"angigkeiten zu Hackages Packages automatisch aufl"osen. Ausserdm verwaltet Cabal Projektmetadaten, wie Lizenz, Author, u.s.w.

\subsubsection{Sandboxing}
\label{sec:sanboxing}

Das Projekt wurde in einer sogenannten Sandbox erstellt. Wenn das Projekt in einer Sandbox erstellt wird, werden alle Abh"angigkeiten des Projekt in einer separaten Paketverwaltung installiert. Das hat den Vorteil, dass "Anderungen an der system globalen Paketverwaltung das Projekt nicht beinflussen. Der Befehl lautet:
\begin{verbatim}
cabal sandbox init
\end{verbatim}

\subsection{Daten einlesen}
\label{sec:readio}

Beim einlesen der Daten sollte mit \verb|ByteString| gearbeitet werden. Dieser Abschnitt beschreibt weshalb.

Bei der Ausf"uhrung der Evaluation werden die Daten jedesmal vom Filesystem eingelesen. Das Modul Pelude bietet daf"ur die Funktion \verb|readFile:: FilePath -> IO String|. \verb|FilePath| ist ein Alias f"ur \verb|String|. Die Funktion nimmt einen Dateipfad und gibt eine IO Action zur"uck. Die IO Action liest den Inhalt des Files und bindet Resultat an einen String.

Ein \verb|String| ist eine Liste. Listen werden Haskell lazy evaluiert. Ein File ist f"ur Haskell also nur eine Liste von Character. Wenn die Listen lazy evaluiert werden sind die Elemente darin nur ein Promise, dass das Element zur Verf"ugung steht, wenn es ben"otigt wird. Die Berechnung des Elements hat noch nicht stattgefunden. Das ist normalerweise kein Problem aber wenn diese Liste ein Stream von der Festplatte ist, ist das Einlesen vergleichweise langsam.

Deshalb gibt es im Paket \verb|bytestring| die Datentypen \verb|Data.ByteString.Strict| und \verb|Data.ByteString.Lazy|. Die Strict-Version l"ost das Problem indem die ganze String in den Arbeitsspeicher eingelesen wird. \verb|Data.ByteString.Lazy| liest die ersten 64KB in den Arbeitsspeicher \cite{Lipovaca}.

Da die Trainings und Testdaten ca. 1.7MB gross sind, wurde f"ur dieses Project \verb|Data.ByteString.Strict| verwendet.

Listing \ref{lst:readio} zeigt wie Daten mit einem ByteString eingelesen werden. Der ByteString wird danach der Funktion \verb|decode| "ubergeben. Das diese ein \verb|Either| wird ein m"oglicher Fehler in der Funktion \verb|toVec| abgefangen.

\begin{lstlisting}[label={lst:readio},caption={Einlesen von Files mit ByteString}]
import Data.Csv
import qualified Data.Vector as V
import qualified Data.ByteString.Lazy as Bl

type Rating = (Int, Int, Double)

basefile = "/home/lukas/oschena/ml-100k/base.csv"

main = do
  putStrLn "Loading Data"
  c <- Bl.readFile basefile
  let csvData = decode NoHeader c :: Either String (V.Vector Rating)
  let v = toVec csvData
  putStrLn $ "Number of Ratings: " ++ (show $ V.length v)

toVec :: Either String (V.Vector Rating)
      -> V.Vector Rating
toVec (Left err) = error err
toVec (Right v) = v
\end{lstlisting}

\subsection{Profiling}
\label{sec:profiling}

Bei den ersten Implementation der Collaborative Filtering Algorithmen ist es oft zu "Memory out of Bound" Exceptions gekommen oder das Programm ben"otigte zu viel Zeit. Um Probleme der Skalierbarkeit zu l"osen wurden Statistiken "uber das Verhalten der Algorithmen zur Laufzeit erstellt.

Der GHC Compiler unterst"utzt Time und Memory Profiling. Der generierte Output zeigt, wieviel Zeit und Speicher eine Funktion verursacht. Das heisst jede Funktion hat ein sogennantes Kostencenter. Jedesmal, wenn die Funktion aufgerufen wird, werden Zeit und Memory zu den vorhandenen Werten im Kostencenter hinzugez"ahlt. Um die Werte in Kostencenter zu berechnen, generiert der Compiler zus"atlichen Code, der die Berechnung ausf"uhrt. Die zu analisierenden Programme m"ussen also mit der entsprechenden Compiler Option ausgef"uhrt werden \cite{Mena}.

Es k"onnen nur Ausf"uhrbare Dateien analisiert werden. In diesem Projekt wurde das Programm \verb|evaluaterecommender| analisiert.

Um das Profiling einzuschalten, m"ussen drei Compiler Optionen gesetzt werden. Die Optionen k"onnen im Cabalfile im ghc-options Property gesetzt werden.
\begin{verbatim}
executable evaluaterecommender
  ghc-options:	-prof -fprof-auto -rtsopts
\end{verbatim}
\begin{description}
\item[-prof] Profiling wird eingeschaltet
\item[-fprof-auto] Alle Funktionen sind Kostencenter
\item[-rtsopts] Erm"oglicht der Runtime Optionen mitzugeben
\end{description}

Alle verwendeten Pakete m"ussen mit der \verb|--enable-library-profiling|- Option kompiliert werden.

Um das Programm zu Analisieren muss es mit der Runtime Option \verb|-p| bei Ausf"uhrung mitgegeben werden. Runtime Optionen k"onnen nach dem Progamm zwischen \verb|+RTS| und \verb|-RTS| mitgegeben werden.  

\begin{verbatim}
$ evaluaterecommender +RTS -p -RTS
\end{verbatim}

Das Programm generiert eine Textdatei \verb|evaluaterecommender.prof|. Diese teilt die Analyse in drei Teile auf.

Im obersten wird beschrieben, wie lange die Ausf"uhrung gedauert hat und wieviel Speicher konsumiert wurde. Im zweiten Teil werden die Funktionen die am meisten Zeit und Speicher ben"otigen mit dem Prozentualen Anteil ausgelistet. Im letzen Teil wird das Aufrufabfolge der Funktionen in Form eines Baumes beschrieben.

\begin{verbatim}
	Wed Dec 24 15:05 2014 Time and Allocation Profiling Report  (Final)

	evaluaterecommender +RTS -p -K100M -RTS

	total time  =        0.74 secs   (741 ticks @ 1000 us, 1 processor)
	total alloc = 1,259,391,232 bytes  (excludes profiling overheads)

COST CENTRE   MODULE  %time %alloc

error            Main     34.7   52.3
updateRow2    Main     27.1   22.1
trainingcases Main      7.8    0.6
iter          Main      5.8    7.7
predict       Main      3.6    4.2

\end{verbatim}

\subsection{Arbeitsspeicher}
\label{sec:memory}

Bei einer Ratingmatrix r mit der Dimension von 1682 mal 943 konsumiert das Programm zu viel Arbeitsspeicher. Es werden 10GB angefordert. Profiling hat gezeigt die Fehler Berechnung viel Arbeitsspeicher konsumiert.

\begin{equation}
  \label{eq:squareerror}
  \sum_{(u,i) \in \kappa} (r_{ui} - q_i^T p_u)^2
\end{equation}

$\kappa$ ist die Menge aller User-Item Paare, f"ur die ein Rating bekannt ist.

\section{Fazit und Ausblick}
\label{sec:fazit}

Die besten Resultate in konnten mit Userbased Collaborative Filtering erreicht werden. Im Gegensatz zu Userbase Collaborative Filtering ist Matrixfaktorisierung schwieriger zu implementieren und zu handhaben. Bei Matrixfaktorisierung mit Gradientenabstieg m"ussen 4 Parameter von Hand optimiert werden.

Die Implementierung von Funk's Gradientenabstiegverfahren hat sich als schwierig erwiesen. Da bei diesem Verfahren die Parametervektoren oft aktualisiert werden wird viel Speicher alloziert und der Garbage Collector muss andauernd aufr"aumen. Deshalb ist es sinnvoll zu pr"ufen, ob das Optimierungsverfahren Funks stochastischer Gradientenabstieg nicht durch ein Verfahren ersetzt werden kann, dass einfacher zu parallelisieren ist. Das Verfahren Alternating Root Squares w"urde sich hierf"ur anieten.

Mit Programmiersprache Haskell k"onnen die Recommender mit wenigen Zeilen Code implementiert werden. Das Package Repository Hackage bietet unter anderem Libraries f"ur den Umgang mit Matrizen und Vectoren. Es enth"alt auch Statistikpakete, die f"ur die Implementierung von Recommenender Systemen genutzt werden k"onnen.

Da die verwendeten Datenstrukturen Immutable sind und die meisten Funktionen keinen Seiteneffekt haben, w"urde sich die Parallelisierung der Algorithmen anbieten.

\bibliographystyle{plain}
\bibliography{a}
\end{document}